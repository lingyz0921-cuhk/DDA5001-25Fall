{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "098b6257",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-05T04:06:49.170156Z",
     "iopub.status.busy": "2025-11-05T04:06:49.169629Z",
     "iopub.status.idle": "2025-11-05T04:06:50.920182Z",
     "shell.execute_reply": "2025-11-05T04:06:50.919285Z"
    },
    "papermill": {
     "duration": 1.755248,
     "end_time": "2025-11-05T04:06:50.921354",
     "exception": false,
     "start_time": "2025-11-05T04:06:49.166106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/LICENSE\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/Kaggle_training.md\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/README.md\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/dataset-metadata-template.json\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/kernel-metadata-template.json\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/main.ipynb\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/src/train.py\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/src/model.py\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/src/configurator.py\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/src/sample.py\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/src/config/finetune_shakespeare.py\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/src/config/train_gpt2.py\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/src/config/eval_gpt2.py\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/src/config/train_shakespeare_char.py\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/src/config/eval_gpt2_medium.py\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/src/config/eval_gpt2_large.py\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/src/config/eval_gpt2_xl.py\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/src/data/openwebtext/prepare.py\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/src/data/openwebtext/readme.md\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/src/data/shakespeare/prepare.py\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/src/data/shakespeare/readme.md\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/src/data/shakespeare_char/train.bin\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/src/data/shakespeare_char/prepare.py\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/src/data/shakespeare_char/readme.md\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/src/data/shakespeare_char/meta.pkl\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/src/data/shakespeare_char/input.txt\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1/src/data/shakespeare_char/val.bin\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/COMMIT_EDITMSG\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/config\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/HEAD\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/index\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/description\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/info/exclude\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/refs/heads/master\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/refs/remotes/origin/master\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/hooks/pre-merge-commit.sample\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/hooks/prepare-commit-msg.sample\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/hooks/update.sample\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/hooks/pre-push.sample\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/hooks/pre-rebase.sample\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/hooks/pre-applypatch.sample\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/hooks/push-to-checkout.sample\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/hooks/pre-commit.sample\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/hooks/commit-msg.sample\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/hooks/post-update.sample\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/hooks/pre-receive.sample\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/hooks/fsmonitor-watchman.sample\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/hooks/applypatch-msg.sample\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/logs/HEAD\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/logs/refs/heads/master\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/logs/refs/remotes/origin/master\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/c5/60d35498a4d90030cb880a0ae069be4fc0f6d0\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/8f/192732ac7a15b1696ca2f61bce7985e36efc37\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/50/824c8a5197086763567e06b57ebe1545a3109f\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/d5/97b79cd3f1245292c3fdd89dd6ae5d00c96646\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/d5/cc6a9a9fcdf5bfcd81839e83d2a22ad5509206\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/1b/ae34f9f1d752c4b13d9f8b428a104426818553\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/05/e48871737274043e1ccc368b99bce65e958933\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/9e/145232555f22c2e0057a44224a47ff8cf4947e\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/39/7c99ec332a53baf27d33bde09b3d70da133932\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/32/9db5e33310fd5d98343e2bca690bfb07317526\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/38/c6e5b61d6f310064ba3bcfd2888b8800f48b06\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/7d/cb3a2d4cc3b48b6283dd46870bfeb78f88aac9\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/12/f9043c81edabcd39894868837b2e277dcd9c8f\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/55/350889d81ed8321bee047ccea9ca793efd17bc\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/e1/9449102ade6b61a59838b45b5b883724f8e8a0\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/49/fe1f79b3bbdeb73749a1081d089a3d9e652a57\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/53/978cb9e2408c9172d4b482afbd48784c3f8b27\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/1e/6c457d8ee51b7d254977631d28848ec5d83993\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/a8/bba9599537cbb34b378399a077b525a87d497f\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/9f/d1621d55b2e0fd268ca1a79cf3b056ed23d16b\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/bd/a25b139f41f66ef95282337d21d820bc252636\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/4c/beaeff29e1be57088b0baa446899b750caf224\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/c6/98f8b60129d793494de058b0dd4e318c0dcb5e\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/90/bc12327688db2ac967ef0011d3826f31aa692d\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/f5/d7052e152f1add168c9561da8a24b50b887774\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/95/eb1bf386564769fb2b97f71fc0d69f448d2f7c\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/f3/9f1d0574e115aaa3ee7758d5c51dce0593049b\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/91/0d123e3bf1c3244cbf2929bec133c84b11a024\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/ca/3686e42272ee9ef8f9b2857a860fd917cbe9dc\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/14/8a4c4fa314f489ecd5629653cc710abd2cd795\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/f6/ddf3397c0a4db2e542c6018a80cf8023c79ed2\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/9d/0db116d1b5876457b286e98d02c69f12d12899\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/f2/7ee269a676404104573e6abd27b84272305922\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/82/c9221af78af69e224ef9e436d46ae4df628c23\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/e8/22fe6e7b02587333de5000da6d145dc96ee7be\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/54/8f828527cf79de8153ce610ec87b4000441f9d\n",
      "/kaggle/input/dda5001-25fall/DDA5001-25Fall-main/.git/objects/2a/9b9752b7f4626c29cb02c83d33e591831ab1c8\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c5a8a26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T04:06:50.927468Z",
     "iopub.status.busy": "2025-11-05T04:06:50.927168Z",
     "iopub.status.idle": "2025-11-05T04:06:51.219834Z",
     "shell.execute_reply": "2025-11-05T04:06:51.219013Z"
    },
    "papermill": {
     "duration": 0.297014,
     "end_time": "2025-11-05T04:06:51.221106",
     "exception": false,
     "start_time": "2025-11-05T04:06:50.924092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/dda5001-25fall/DDA5001-25Fall-main/p1 /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30eafc28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T04:06:51.227331Z",
     "iopub.status.busy": "2025-11-05T04:06:51.226676Z",
     "iopub.status.idle": "2025-11-05T04:06:51.232804Z",
     "shell.execute_reply": "2025-11-05T04:06:51.232176Z"
    },
    "papermill": {
     "duration": 0.010336,
     "end_time": "2025-11-05T04:06:51.233820",
     "exception": false,
     "start_time": "2025-11-05T04:06:51.223484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/p1/src\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/p1/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "424b1442",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T04:06:51.238997Z",
     "iopub.status.busy": "2025-11-05T04:06:51.238781Z",
     "iopub.status.idle": "2025-11-05T04:06:51.361048Z",
     "shell.execute_reply": "2025-11-05T04:06:51.360140Z"
    },
    "papermill": {
     "duration": 0.126296,
     "end_time": "2025-11-05T04:06:51.362297",
     "exception": false,
     "start_time": "2025-11-05T04:06:51.236001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 52\r\n",
      "drwxr-xr-x 2 root root  4096 Nov  5 04:06 config\r\n",
      "-rw-r--r-- 1 root root  1758 Nov  5 04:06 configurator.py\r\n",
      "drwxr-xr-x 5 root root  4096 Nov  5 04:06 data\r\n",
      "-rw-r--r-- 1 root root 16345 Nov  5 04:06 model.py\r\n",
      "-rw-r--r-- 1 root root  4568 Nov  5 04:06 sample.py\r\n",
      "-rw-r--r-- 1 root root 15942 Nov  5 04:06 train.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4b902bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T04:06:51.367706Z",
     "iopub.status.busy": "2025-11-05T04:06:51.367459Z",
     "iopub.status.idle": "2025-11-05T04:06:51.605759Z",
     "shell.execute_reply": "2025-11-05T04:06:51.604989Z"
    },
    "papermill": {
     "duration": 0.24264,
     "end_time": "2025-11-05T04:06:51.607156",
     "exception": false,
     "start_time": "2025-11-05T04:06:51.364516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!sed -i 's/student_id = \"225040023\"/student_id = \"225040023\"/g' train.py\n",
    "!sed -i 's/student_id = \"225040023\"/student_id = \"225040023\"/g' sample.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed22169b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T04:06:51.612720Z",
     "iopub.status.busy": "2025-11-05T04:06:51.612411Z",
     "iopub.status.idle": "2025-11-05T04:06:51.616096Z",
     "shell.execute_reply": "2025-11-05T04:06:51.615392Z"
    },
    "papermill": {
     "duration": 0.007665,
     "end_time": "2025-11-05T04:06:51.617199",
     "exception": false,
     "start_time": "2025-11-05T04:06:51.609534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install numpy transformers datasets tiktoken wandb tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cf62b86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T04:06:51.622680Z",
     "iopub.status.busy": "2025-11-05T04:06:51.622044Z",
     "iopub.status.idle": "2025-11-05T04:06:51.738285Z",
     "shell.execute_reply": "2025-11-05T04:06:51.737612Z"
    },
    "papermill": {
     "duration": 0.119992,
     "end_time": "2025-11-05T04:06:51.739387",
     "exception": false,
     "start_time": "2025-11-05T04:06:51.619395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3288\r\n",
      "-rw-r--r-- 1 root root 1115394 Nov  5 04:06 input.txt\r\n",
      "-rw-r--r-- 1 root root     703 Nov  5 04:06 meta.pkl\r\n",
      "-rw-r--r-- 1 root root    2344 Nov  5 04:06 prepare.py\r\n",
      "-rw-r--r-- 1 root root     209 Nov  5 04:06 readme.md\r\n",
      "-rw-r--r-- 1 root root 2007708 Nov  5 04:06 train.bin\r\n",
      "-rw-r--r-- 1 root root  223080 Nov  5 04:06 val.bin\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l data/shakespeare_char/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad3bd8d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T04:06:51.744869Z",
     "iopub.status.busy": "2025-11-05T04:06:51.744639Z",
     "iopub.status.idle": "2025-11-05T07:23:34.491896Z",
     "shell.execute_reply": "2025-11-05T07:23:34.491097Z"
    },
    "papermill": {
     "duration": 11802.751643,
     "end_time": "2025-11-05T07:23:34.493370",
     "exception": false,
     "start_time": "2025-11-05T04:06:51.741727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding config with config/train_shakespeare_char.py:\r\n",
      "# train a miniature character-level shakespeare model\r\n",
      "# good for debugging and playing on macbooks and such\r\n",
      "\r\n",
      "out_dir = 'out-shakespeare-char'\r\n",
      "eval_interval = 250 # keep frequent because we'll overfit\r\n",
      "eval_iters = 200\r\n",
      "log_interval = 10 # don't print too too often\r\n",
      "\r\n",
      "# we expect to overfit on this small dataset, so only save when val improves\r\n",
      "always_save_checkpoint = False\r\n",
      "\r\n",
      "wandb_log = False # override via command line if you like\r\n",
      "wandb_project = 'shakespeare-char'\r\n",
      "wandb_run_name = 'mini-gpt'\r\n",
      "\r\n",
      "dataset = 'shakespeare_char'\r\n",
      "gradient_accumulation_steps = 1\r\n",
      "batch_size = 16\r\n",
      "block_size = 256 # context of up to 256 previous characters\r\n",
      "\r\n",
      "# baby GPT model :)\r\n",
      "n_layer = 24\r\n",
      "n_head = 16\r\n",
      "n_embd = 1024\r\n",
      "dropout = 0.2\r\n",
      "\r\n",
      "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\r\n",
      "max_iters = 5000\r\n",
      "lr_decay_iters = 5000 # make equal to max_iters usually\r\n",
      "min_lr = 1e-4 # learning_rate / 10 usually\r\n",
      "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\r\n",
      "\r\n",
      "warmup_iters = 100 # not super necessary potentially\r\n",
      "\r\n",
      "# on macbook also add\r\n",
      "# device = 'cpu'  # run on cpu only\r\n",
      "# compile = False # do not torch compile the model\r\n",
      "\r\n",
      "tokens per iteration will be: 4,096\r\n",
      "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\r\n",
      "Initializing a new model from scratch\r\n",
      "number of parameters: 302.11M\r\n",
      "/kaggle/working/p1/src/train.py:204: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\r\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\r\n",
      "num decayed parameter tensors: 98, with 302,318,592 parameters\r\n",
      "num non-decayed parameter tensors: 49, with 50,176 parameters\r\n",
      "using fused AdamW: True\r\n",
      "step 0: train loss 4.4777, val loss 4.4797\r\n",
      "iter 0: loss 4.4804, time 204119.89ms, mfu -100.00%\r\n",
      "iter 10: loss 3.3118, time 1468.81ms, mfu 1.69%\r\n",
      "iter 20: loss 3.0243, time 1469.92ms, mfu 1.69%\r\n",
      "iter 30: loss 2.7304, time 1469.96ms, mfu 1.69%\r\n",
      "iter 40: loss 2.6777, time 1469.68ms, mfu 1.69%\r\n",
      "iter 50: loss 2.6039, time 1468.45ms, mfu 1.69%\r\n",
      "iter 60: loss 2.5809, time 1469.61ms, mfu 1.69%\r\n",
      "iter 70: loss 2.5553, time 1469.69ms, mfu 1.69%\r\n",
      "iter 80: loss 2.5913, time 1469.65ms, mfu 1.69%\r\n",
      "iter 90: loss 2.5249, time 1469.27ms, mfu 1.69%\r\n",
      "iter 100: loss 2.5473, time 1470.20ms, mfu 1.69%\r\n",
      "iter 110: loss 2.5514, time 1468.60ms, mfu 1.69%\r\n",
      "iter 120: loss 2.5138, time 1469.46ms, mfu 1.69%\r\n",
      "iter 130: loss 2.4807, time 1469.05ms, mfu 1.69%\r\n",
      "iter 140: loss 2.5105, time 1469.74ms, mfu 1.69%\r\n",
      "iter 150: loss 2.4866, time 1468.94ms, mfu 1.69%\r\n",
      "iter 160: loss 2.4863, time 1471.74ms, mfu 1.69%\r\n",
      "iter 170: loss 2.5234, time 1470.46ms, mfu 1.69%\r\n",
      "iter 180: loss 2.4572, time 1469.76ms, mfu 1.69%\r\n",
      "iter 190: loss 2.4357, time 1469.94ms, mfu 1.69%\r\n",
      "iter 200: loss 2.4142, time 1470.34ms, mfu 1.69%\r\n",
      "iter 210: loss 2.3489, time 1471.40ms, mfu 1.69%\r\n",
      "iter 220: loss 2.3031, time 1470.17ms, mfu 1.69%\r\n",
      "iter 230: loss 2.2829, time 1470.30ms, mfu 1.69%\r\n",
      "iter 240: loss 2.2899, time 1469.97ms, mfu 1.69%\r\n",
      "step 250: train loss 2.2049, val loss 2.2527\r\n",
      "saving checkpoint to out-shakespeare-char\r\n",
      "iter 250: loss 2.2507, time 208836.01ms, mfu 1.52%\r\n",
      "iter 260: loss 2.2666, time 1470.47ms, mfu 1.54%\r\n",
      "iter 270: loss 2.1956, time 1470.88ms, mfu 1.55%\r\n",
      "iter 280: loss 2.1999, time 1471.69ms, mfu 1.56%\r\n",
      "iter 290: loss 2.1960, time 1472.09ms, mfu 1.58%\r\n",
      "iter 300: loss 2.1773, time 1471.84ms, mfu 1.59%\r\n",
      "iter 310: loss 2.1457, time 1472.40ms, mfu 1.60%\r\n",
      "iter 320: loss 2.1205, time 1473.22ms, mfu 1.61%\r\n",
      "iter 330: loss 2.1322, time 1474.10ms, mfu 1.61%\r\n",
      "iter 340: loss 2.1142, time 1473.41ms, mfu 1.62%\r\n",
      "iter 350: loss 2.1263, time 1474.74ms, mfu 1.63%\r\n",
      "iter 360: loss 2.0854, time 1472.80ms, mfu 1.63%\r\n",
      "iter 370: loss 2.0433, time 1474.17ms, mfu 1.64%\r\n",
      "iter 380: loss 2.0404, time 1473.30ms, mfu 1.64%\r\n",
      "iter 390: loss 2.0889, time 1475.14ms, mfu 1.65%\r\n",
      "iter 400: loss 2.0320, time 1473.11ms, mfu 1.65%\r\n",
      "iter 410: loss 2.0209, time 1474.26ms, mfu 1.65%\r\n",
      "iter 420: loss 2.0416, time 1473.02ms, mfu 1.66%\r\n",
      "iter 430: loss 2.0454, time 1474.21ms, mfu 1.66%\r\n",
      "iter 440: loss 2.0302, time 1474.75ms, mfu 1.66%\r\n",
      "iter 450: loss 2.0093, time 1473.79ms, mfu 1.66%\r\n",
      "iter 460: loss 2.0022, time 1474.53ms, mfu 1.66%\r\n",
      "iter 470: loss 1.9841, time 1473.91ms, mfu 1.67%\r\n",
      "iter 480: loss 2.0317, time 1473.33ms, mfu 1.67%\r\n",
      "iter 490: loss 1.9965, time 1475.34ms, mfu 1.67%\r\n",
      "step 500: train loss 1.9278, val loss 2.0375\r\n",
      "saving checkpoint to out-shakespeare-char\r\n",
      "iter 500: loss 1.9353, time 213141.10ms, mfu 1.50%\r\n",
      "iter 510: loss 1.9518, time 1474.95ms, mfu 1.52%\r\n",
      "iter 520: loss 1.9613, time 1473.40ms, mfu 1.54%\r\n",
      "iter 530: loss 1.9373, time 1474.12ms, mfu 1.55%\r\n",
      "iter 540: loss 1.9771, time 1474.21ms, mfu 1.56%\r\n",
      "iter 550: loss 1.9840, time 1474.11ms, mfu 1.58%\r\n",
      "iter 560: loss 1.9700, time 1473.00ms, mfu 1.59%\r\n",
      "iter 570: loss 1.9709, time 1474.74ms, mfu 1.60%\r\n",
      "iter 580: loss 1.9209, time 1473.88ms, mfu 1.60%\r\n",
      "iter 590: loss 1.9771, time 1474.43ms, mfu 1.61%\r\n",
      "iter 600: loss 1.9485, time 1474.93ms, mfu 1.62%\r\n",
      "iter 610: loss 1.9208, time 1474.81ms, mfu 1.63%\r\n",
      "iter 620: loss 1.9024, time 1474.59ms, mfu 1.63%\r\n",
      "iter 630: loss 1.9077, time 1474.66ms, mfu 1.64%\r\n",
      "iter 640: loss 1.9175, time 1473.80ms, mfu 1.64%\r\n",
      "iter 650: loss 1.8872, time 1474.36ms, mfu 1.64%\r\n",
      "iter 660: loss 1.9155, time 1474.76ms, mfu 1.65%\r\n",
      "iter 670: loss 1.9387, time 1475.60ms, mfu 1.65%\r\n",
      "iter 680: loss 1.9295, time 1474.27ms, mfu 1.65%\r\n",
      "iter 690: loss 1.9080, time 1473.73ms, mfu 1.66%\r\n",
      "iter 700: loss 1.9512, time 1474.02ms, mfu 1.66%\r\n",
      "iter 710: loss 1.9259, time 1473.77ms, mfu 1.66%\r\n",
      "iter 720: loss 1.9379, time 1474.09ms, mfu 1.66%\r\n",
      "iter 730: loss 1.9059, time 1474.22ms, mfu 1.67%\r\n",
      "iter 740: loss 1.8978, time 1474.15ms, mfu 1.67%\r\n",
      "step 750: train loss 1.8060, val loss 1.9496\r\n",
      "saving checkpoint to out-shakespeare-char\r\n",
      "iter 750: loss 1.9020, time 212786.93ms, mfu 1.50%\r\n",
      "iter 760: loss 1.9388, time 1474.00ms, mfu 1.52%\r\n",
      "iter 770: loss 1.8934, time 1475.37ms, mfu 1.54%\r\n",
      "iter 780: loss 1.8419, time 1474.57ms, mfu 1.55%\r\n",
      "iter 790: loss 1.8711, time 1474.73ms, mfu 1.56%\r\n",
      "iter 800: loss 1.8356, time 1474.67ms, mfu 1.58%\r\n",
      "iter 810: loss 1.8352, time 1475.23ms, mfu 1.59%\r\n",
      "iter 820: loss 1.8923, time 1475.90ms, mfu 1.59%\r\n",
      "iter 830: loss 1.8479, time 1473.69ms, mfu 1.60%\r\n",
      "iter 840: loss 1.8326, time 1475.40ms, mfu 1.61%\r\n",
      "iter 850: loss 1.9170, time 1473.72ms, mfu 1.62%\r\n",
      "iter 860: loss 1.8615, time 1473.45ms, mfu 1.62%\r\n",
      "iter 870: loss 1.8034, time 1472.75ms, mfu 1.63%\r\n",
      "iter 880: loss 1.8457, time 1474.49ms, mfu 1.64%\r\n",
      "iter 890: loss 1.7966, time 1473.44ms, mfu 1.64%\r\n",
      "iter 900: loss 1.8545, time 1474.56ms, mfu 1.64%\r\n",
      "iter 910: loss 1.9031, time 1474.89ms, mfu 1.65%\r\n",
      "iter 920: loss 1.8495, time 1475.16ms, mfu 1.65%\r\n",
      "iter 930: loss 1.8244, time 1474.28ms, mfu 1.65%\r\n",
      "iter 940: loss 1.8260, time 1474.88ms, mfu 1.66%\r\n",
      "iter 950: loss 1.8088, time 1474.28ms, mfu 1.66%\r\n",
      "iter 960: loss 1.8121, time 1475.12ms, mfu 1.66%\r\n",
      "iter 970: loss 1.8284, time 1474.63ms, mfu 1.66%\r\n",
      "iter 980: loss 1.8255, time 1473.98ms, mfu 1.67%\r\n",
      "iter 990: loss 1.8500, time 1474.25ms, mfu 1.67%\r\n",
      "step 1000: train loss 1.7517, val loss 1.9232\r\n",
      "saving checkpoint to out-shakespeare-char\r\n",
      "iter 1000: loss 1.8323, time 213153.07ms, mfu 1.50%\r\n",
      "iter 1010: loss 1.7739, time 1473.49ms, mfu 1.52%\r\n",
      "iter 1020: loss 1.7871, time 1473.89ms, mfu 1.54%\r\n",
      "iter 1030: loss 1.8011, time 1474.02ms, mfu 1.55%\r\n",
      "iter 1040: loss 1.8170, time 1474.66ms, mfu 1.56%\r\n",
      "iter 1050: loss 1.8550, time 1474.83ms, mfu 1.58%\r\n",
      "iter 1060: loss 1.8216, time 1474.11ms, mfu 1.59%\r\n",
      "iter 1070: loss 1.7803, time 1474.08ms, mfu 1.60%\r\n",
      "iter 1080: loss 1.8513, time 1473.56ms, mfu 1.60%\r\n",
      "iter 1090: loss 1.8051, time 1475.55ms, mfu 1.61%\r\n",
      "iter 1100: loss 1.8528, time 1473.98ms, mfu 1.62%\r\n",
      "iter 1110: loss 1.8506, time 1473.82ms, mfu 1.62%\r\n",
      "iter 1120: loss 1.7960, time 1474.08ms, mfu 1.63%\r\n",
      "iter 1130: loss 1.8283, time 1473.32ms, mfu 1.64%\r\n",
      "iter 1140: loss 1.8167, time 1474.77ms, mfu 1.64%\r\n",
      "iter 1150: loss 1.8343, time 1474.27ms, mfu 1.64%\r\n",
      "iter 1160: loss 1.7720, time 1474.37ms, mfu 1.65%\r\n",
      "iter 1170: loss 1.7917, time 1475.25ms, mfu 1.65%\r\n",
      "iter 1180: loss 1.8018, time 1474.59ms, mfu 1.65%\r\n",
      "iter 1190: loss 1.8125, time 1474.79ms, mfu 1.66%\r\n",
      "iter 1200: loss 1.7778, time 1473.74ms, mfu 1.66%\r\n",
      "iter 1210: loss 1.8140, time 1474.18ms, mfu 1.66%\r\n",
      "iter 1220: loss 1.7786, time 1475.42ms, mfu 1.66%\r\n",
      "iter 1230: loss 1.7302, time 1474.60ms, mfu 1.67%\r\n",
      "iter 1240: loss 1.8129, time 1475.33ms, mfu 1.67%\r\n",
      "step 1250: train loss 1.7249, val loss 1.9107\r\n",
      "saving checkpoint to out-shakespeare-char\r\n",
      "iter 1250: loss 1.8027, time 212774.47ms, mfu 1.50%\r\n",
      "iter 1260: loss 1.7650, time 1475.53ms, mfu 1.52%\r\n",
      "iter 1270: loss 1.7986, time 1473.55ms, mfu 1.54%\r\n",
      "iter 1280: loss 1.7644, time 1472.49ms, mfu 1.55%\r\n",
      "iter 1290: loss 1.8023, time 1472.91ms, mfu 1.56%\r\n",
      "iter 1300: loss 1.7870, time 1475.31ms, mfu 1.58%\r\n",
      "iter 1310: loss 1.8280, time 1475.14ms, mfu 1.59%\r\n",
      "iter 1320: loss 1.7950, time 1474.02ms, mfu 1.60%\r\n",
      "iter 1330: loss 1.7958, time 1473.55ms, mfu 1.60%\r\n",
      "iter 1340: loss 1.8210, time 1474.33ms, mfu 1.61%\r\n",
      "iter 1350: loss 1.8282, time 1474.75ms, mfu 1.62%\r\n",
      "iter 1360: loss 1.7253, time 1474.46ms, mfu 1.62%\r\n",
      "iter 1370: loss 1.7761, time 1473.80ms, mfu 1.63%\r\n",
      "iter 1380: loss 1.8534, time 1474.92ms, mfu 1.64%\r\n",
      "iter 1390: loss 1.8029, time 1474.96ms, mfu 1.64%\r\n",
      "iter 1400: loss 1.8121, time 1474.94ms, mfu 1.64%\r\n",
      "iter 1410: loss 1.8252, time 1474.65ms, mfu 1.65%\r\n",
      "iter 1420: loss 1.7796, time 1474.83ms, mfu 1.65%\r\n",
      "iter 1430: loss 1.7658, time 1474.80ms, mfu 1.65%\r\n",
      "iter 1440: loss 1.7690, time 1472.79ms, mfu 1.66%\r\n",
      "iter 1450: loss 1.7945, time 1474.68ms, mfu 1.66%\r\n",
      "iter 1460: loss 1.8015, time 1474.01ms, mfu 1.66%\r\n",
      "iter 1470: loss 1.7514, time 1474.46ms, mfu 1.66%\r\n",
      "iter 1480: loss 1.8718, time 1473.73ms, mfu 1.67%\r\n",
      "iter 1490: loss 1.7695, time 1474.01ms, mfu 1.67%\r\n",
      "step 1500: train loss 1.7241, val loss 1.8840\r\n",
      "saving checkpoint to out-shakespeare-char\r\n",
      "iter 1500: loss 1.7840, time 212864.68ms, mfu 1.50%\r\n",
      "iter 1510: loss 1.8444, time 1474.12ms, mfu 1.52%\r\n",
      "iter 1520: loss 1.8252, time 1473.59ms, mfu 1.54%\r\n",
      "iter 1530: loss 1.7882, time 1474.69ms, mfu 1.55%\r\n",
      "iter 1540: loss 1.6857, time 1474.13ms, mfu 1.56%\r\n",
      "iter 1550: loss 1.8154, time 1473.07ms, mfu 1.58%\r\n",
      "iter 1560: loss 1.8320, time 1474.81ms, mfu 1.59%\r\n",
      "iter 1570: loss 1.7931, time 1474.60ms, mfu 1.60%\r\n",
      "iter 1580: loss 1.7922, time 1474.53ms, mfu 1.60%\r\n",
      "iter 1590: loss 1.7363, time 1474.03ms, mfu 1.61%\r\n",
      "iter 1600: loss 1.7752, time 1475.30ms, mfu 1.62%\r\n",
      "iter 1610: loss 1.8091, time 1474.76ms, mfu 1.62%\r\n",
      "iter 1620: loss 1.7396, time 1473.49ms, mfu 1.63%\r\n",
      "iter 1630: loss 1.7998, time 1474.47ms, mfu 1.64%\r\n",
      "iter 1640: loss 1.8364, time 1475.71ms, mfu 1.64%\r\n",
      "iter 1650: loss 1.8383, time 1474.54ms, mfu 1.64%\r\n",
      "iter 1660: loss 1.8312, time 1473.98ms, mfu 1.65%\r\n",
      "iter 1670: loss 1.7876, time 1474.55ms, mfu 1.65%\r\n",
      "iter 1680: loss 1.7793, time 1475.40ms, mfu 1.65%\r\n",
      "iter 1690: loss 1.7176, time 1475.06ms, mfu 1.66%\r\n",
      "iter 1700: loss 1.7183, time 1474.56ms, mfu 1.66%\r\n",
      "iter 1710: loss 1.8051, time 1475.07ms, mfu 1.66%\r\n",
      "iter 1720: loss 1.7285, time 1474.66ms, mfu 1.66%\r\n",
      "iter 1730: loss 1.7957, time 1474.11ms, mfu 1.67%\r\n",
      "iter 1740: loss 1.8103, time 1475.43ms, mfu 1.67%\r\n",
      "step 1750: train loss 1.6956, val loss 1.8730\r\n",
      "saving checkpoint to out-shakespeare-char\r\n",
      "iter 1750: loss 1.7613, time 211151.50ms, mfu 1.50%\r\n",
      "iter 1760: loss 1.7558, time 1474.80ms, mfu 1.52%\r\n",
      "iter 1770: loss 1.8387, time 1475.06ms, mfu 1.54%\r\n",
      "iter 1780: loss 1.7744, time 1473.63ms, mfu 1.55%\r\n",
      "iter 1790: loss 1.8614, time 1473.87ms, mfu 1.56%\r\n",
      "iter 1800: loss 1.8296, time 1473.66ms, mfu 1.57%\r\n",
      "iter 1810: loss 1.7774, time 1475.12ms, mfu 1.59%\r\n",
      "iter 1820: loss 1.8578, time 1473.69ms, mfu 1.60%\r\n",
      "iter 1830: loss 1.7740, time 1473.69ms, mfu 1.60%\r\n",
      "iter 1840: loss 1.7456, time 1474.44ms, mfu 1.61%\r\n",
      "iter 1850: loss 1.8050, time 1474.30ms, mfu 1.62%\r\n",
      "iter 1860: loss 1.8362, time 1474.74ms, mfu 1.62%\r\n",
      "iter 1870: loss 1.7682, time 1474.08ms, mfu 1.63%\r\n",
      "iter 1880: loss 1.7562, time 1474.01ms, mfu 1.64%\r\n",
      "iter 1890: loss 1.8087, time 1474.47ms, mfu 1.64%\r\n",
      "iter 1900: loss 1.7776, time 1475.12ms, mfu 1.64%\r\n",
      "iter 1910: loss 1.7601, time 1474.23ms, mfu 1.65%\r\n",
      "iter 1920: loss 1.8287, time 1473.74ms, mfu 1.65%\r\n",
      "iter 1930: loss 1.7164, time 1473.92ms, mfu 1.65%\r\n",
      "iter 1940: loss 1.7411, time 1473.31ms, mfu 1.66%\r\n",
      "iter 1950: loss 1.7522, time 1474.45ms, mfu 1.66%\r\n",
      "iter 1960: loss 1.7055, time 1473.38ms, mfu 1.66%\r\n",
      "iter 1970: loss 1.7596, time 1474.17ms, mfu 1.66%\r\n",
      "iter 1980: loss 1.7641, time 1474.12ms, mfu 1.67%\r\n",
      "iter 1990: loss 1.7752, time 1475.20ms, mfu 1.67%\r\n",
      "step 2000: train loss 1.6821, val loss 1.8446\r\n",
      "saving checkpoint to out-shakespeare-char\r\n",
      "iter 2000: loss 1.8272, time 213814.57ms, mfu 1.50%\r\n",
      "iter 2010: loss 1.6661, time 1474.55ms, mfu 1.52%\r\n",
      "iter 2020: loss 1.7674, time 1474.76ms, mfu 1.54%\r\n",
      "iter 2030: loss 1.7659, time 1473.58ms, mfu 1.55%\r\n",
      "iter 2040: loss 1.7505, time 1474.64ms, mfu 1.56%\r\n",
      "iter 2050: loss 1.8224, time 1472.80ms, mfu 1.58%\r\n",
      "iter 2060: loss 1.7912, time 1474.52ms, mfu 1.59%\r\n",
      "iter 2070: loss 1.7437, time 1474.12ms, mfu 1.60%\r\n",
      "iter 2080: loss 1.8181, time 1474.14ms, mfu 1.60%\r\n",
      "iter 2090: loss 1.7621, time 1474.56ms, mfu 1.61%\r\n",
      "iter 2100: loss 1.8129, time 1473.95ms, mfu 1.62%\r\n",
      "iter 2110: loss 1.7643, time 1473.52ms, mfu 1.63%\r\n",
      "iter 2120: loss 1.8312, time 1474.56ms, mfu 1.63%\r\n",
      "iter 2130: loss 1.8699, time 1474.09ms, mfu 1.64%\r\n",
      "iter 2140: loss 1.7705, time 1474.02ms, mfu 1.64%\r\n",
      "iter 2150: loss 1.7521, time 1474.29ms, mfu 1.64%\r\n",
      "iter 2160: loss 1.8361, time 1473.10ms, mfu 1.65%\r\n",
      "iter 2170: loss 1.7538, time 1474.70ms, mfu 1.65%\r\n",
      "iter 2180: loss 1.7566, time 1473.10ms, mfu 1.65%\r\n",
      "iter 2190: loss 1.8043, time 1474.41ms, mfu 1.66%\r\n",
      "iter 2200: loss 1.7646, time 1474.57ms, mfu 1.66%\r\n",
      "iter 2210: loss 1.7643, time 1475.41ms, mfu 1.66%\r\n",
      "iter 2220: loss 1.7614, time 1474.68ms, mfu 1.66%\r\n",
      "iter 2230: loss 1.6767, time 1475.09ms, mfu 1.67%\r\n",
      "iter 2240: loss 1.8468, time 1474.40ms, mfu 1.67%\r\n",
      "step 2250: train loss 1.6780, val loss 1.8526\r\n",
      "iter 2250: loss 1.7553, time 204883.61ms, mfu 1.50%\r\n",
      "iter 2260: loss 1.7169, time 1474.23ms, mfu 1.52%\r\n",
      "iter 2270: loss 1.7983, time 1474.81ms, mfu 1.54%\r\n",
      "iter 2280: loss 1.8172, time 1474.89ms, mfu 1.55%\r\n",
      "iter 2290: loss 1.7734, time 1474.66ms, mfu 1.56%\r\n",
      "iter 2300: loss 1.7673, time 1474.39ms, mfu 1.57%\r\n",
      "iter 2310: loss 1.7456, time 1474.82ms, mfu 1.59%\r\n",
      "iter 2320: loss 1.7776, time 1473.75ms, mfu 1.60%\r\n",
      "iter 2330: loss 1.8218, time 1474.30ms, mfu 1.60%\r\n",
      "iter 2340: loss 1.7835, time 1474.33ms, mfu 1.61%\r\n",
      "iter 2350: loss 1.7769, time 1474.51ms, mfu 1.62%\r\n",
      "iter 2360: loss 1.7082, time 1473.96ms, mfu 1.62%\r\n",
      "iter 2370: loss 1.7616, time 1473.73ms, mfu 1.63%\r\n",
      "iter 2380: loss 1.7828, time 1474.47ms, mfu 1.64%\r\n",
      "iter 2390: loss 1.8513, time 1473.87ms, mfu 1.64%\r\n",
      "iter 2400: loss 1.7071, time 1474.60ms, mfu 1.64%\r\n",
      "iter 2410: loss 1.7509, time 1473.70ms, mfu 1.65%\r\n",
      "iter 2420: loss 1.8449, time 1473.67ms, mfu 1.65%\r\n",
      "iter 2430: loss 1.7898, time 1474.73ms, mfu 1.65%\r\n",
      "iter 2440: loss 1.7478, time 1472.33ms, mfu 1.66%\r\n",
      "iter 2450: loss 1.7505, time 1474.04ms, mfu 1.66%\r\n",
      "iter 2460: loss 1.8102, time 1474.97ms, mfu 1.66%\r\n",
      "iter 2470: loss 1.7682, time 1473.40ms, mfu 1.66%\r\n",
      "iter 2480: loss 1.7945, time 1474.49ms, mfu 1.67%\r\n",
      "iter 2490: loss 1.8019, time 1474.84ms, mfu 1.67%\r\n",
      "step 2500: train loss 1.6591, val loss 1.8496\r\n",
      "iter 2500: loss 1.7709, time 204964.83ms, mfu 1.50%\r\n",
      "iter 2510: loss 1.8097, time 1475.36ms, mfu 1.52%\r\n",
      "iter 2520: loss 1.7487, time 1472.85ms, mfu 1.54%\r\n",
      "iter 2530: loss 1.7916, time 1473.71ms, mfu 1.55%\r\n",
      "iter 2540: loss 1.8398, time 1474.22ms, mfu 1.56%\r\n",
      "iter 2550: loss 1.7120, time 1473.73ms, mfu 1.58%\r\n",
      "iter 2560: loss 1.7530, time 1475.01ms, mfu 1.59%\r\n",
      "iter 2570: loss 1.7186, time 1475.08ms, mfu 1.60%\r\n",
      "iter 2580: loss 1.7233, time 1474.34ms, mfu 1.60%\r\n",
      "iter 2590: loss 1.7736, time 1474.60ms, mfu 1.61%\r\n",
      "iter 2600: loss 1.7920, time 1473.02ms, mfu 1.62%\r\n",
      "iter 2610: loss 1.7611, time 1473.80ms, mfu 1.63%\r\n",
      "iter 2620: loss 1.7414, time 1474.39ms, mfu 1.63%\r\n",
      "iter 2630: loss 1.7797, time 1475.41ms, mfu 1.64%\r\n",
      "iter 2640: loss 1.7722, time 1473.07ms, mfu 1.64%\r\n",
      "iter 2650: loss 1.8252, time 1475.19ms, mfu 1.64%\r\n",
      "iter 2660: loss 1.8075, time 1474.17ms, mfu 1.65%\r\n",
      "iter 2670: loss 1.7696, time 1474.04ms, mfu 1.65%\r\n",
      "iter 2680: loss 1.7982, time 1474.26ms, mfu 1.65%\r\n",
      "iter 2690: loss 1.7728, time 1474.23ms, mfu 1.66%\r\n",
      "iter 2700: loss 1.7307, time 1474.11ms, mfu 1.66%\r\n",
      "iter 2710: loss 1.7671, time 1474.19ms, mfu 1.66%\r\n",
      "iter 2720: loss 1.7002, time 1474.23ms, mfu 1.66%\r\n",
      "iter 2730: loss 1.7452, time 1473.70ms, mfu 1.67%\r\n",
      "iter 2740: loss 1.7532, time 1473.89ms, mfu 1.67%\r\n",
      "step 2750: train loss 1.6479, val loss 1.8387\r\n",
      "saving checkpoint to out-shakespeare-char\r\n",
      "iter 2750: loss 1.7726, time 216072.55ms, mfu 1.50%\r\n",
      "iter 2760: loss 1.7794, time 1473.10ms, mfu 1.52%\r\n",
      "iter 2770: loss 1.7777, time 1474.49ms, mfu 1.54%\r\n",
      "iter 2780: loss 1.7834, time 1474.77ms, mfu 1.55%\r\n",
      "iter 2790: loss 1.8844, time 1474.76ms, mfu 1.56%\r\n",
      "iter 2800: loss 1.7010, time 1474.24ms, mfu 1.58%\r\n",
      "iter 2810: loss 1.7488, time 1473.81ms, mfu 1.59%\r\n",
      "iter 2820: loss 1.7106, time 1474.70ms, mfu 1.60%\r\n",
      "iter 2830: loss 1.7612, time 1473.75ms, mfu 1.60%\r\n",
      "iter 2840: loss 1.7323, time 1473.42ms, mfu 1.61%\r\n",
      "iter 2850: loss 1.6754, time 1474.12ms, mfu 1.62%\r\n",
      "iter 2860: loss 1.8082, time 1473.71ms, mfu 1.63%\r\n",
      "iter 2870: loss 1.7008, time 1475.40ms, mfu 1.63%\r\n",
      "iter 2880: loss 1.7411, time 1473.92ms, mfu 1.64%\r\n",
      "iter 2890: loss 1.7509, time 1474.92ms, mfu 1.64%\r\n",
      "iter 2900: loss 1.7058, time 1473.68ms, mfu 1.64%\r\n",
      "iter 2910: loss 1.6867, time 1475.19ms, mfu 1.65%\r\n",
      "iter 2920: loss 1.7333, time 1474.31ms, mfu 1.65%\r\n",
      "iter 2930: loss 1.7604, time 1473.55ms, mfu 1.65%\r\n",
      "iter 2940: loss 1.7257, time 1473.59ms, mfu 1.66%\r\n",
      "iter 2950: loss 1.7683, time 1473.24ms, mfu 1.66%\r\n",
      "iter 2960: loss 1.8015, time 1474.68ms, mfu 1.66%\r\n",
      "iter 2970: loss 1.7132, time 1474.47ms, mfu 1.66%\r\n",
      "iter 2980: loss 1.7250, time 1474.95ms, mfu 1.67%\r\n",
      "iter 2990: loss 1.7016, time 1474.51ms, mfu 1.67%\r\n",
      "step 3000: train loss 1.6352, val loss 1.8339\r\n",
      "saving checkpoint to out-shakespeare-char\r\n",
      "iter 3000: loss 1.7556, time 216075.89ms, mfu 1.50%\r\n",
      "iter 3010: loss 1.7249, time 1473.83ms, mfu 1.52%\r\n",
      "iter 3020: loss 1.7212, time 1474.72ms, mfu 1.54%\r\n",
      "iter 3030: loss 1.8043, time 1473.59ms, mfu 1.55%\r\n",
      "iter 3040: loss 1.7289, time 1474.15ms, mfu 1.56%\r\n",
      "iter 3050: loss 1.7783, time 1475.14ms, mfu 1.58%\r\n",
      "iter 3060: loss 1.7424, time 1474.15ms, mfu 1.59%\r\n",
      "iter 3070: loss 1.7184, time 1474.48ms, mfu 1.60%\r\n",
      "iter 3080: loss 1.7239, time 1473.48ms, mfu 1.60%\r\n",
      "iter 3090: loss 1.6724, time 1475.41ms, mfu 1.61%\r\n",
      "iter 3100: loss 1.7484, time 1474.09ms, mfu 1.62%\r\n",
      "iter 3110: loss 1.7037, time 1474.11ms, mfu 1.62%\r\n",
      "iter 3120: loss 1.6763, time 1475.24ms, mfu 1.63%\r\n",
      "iter 3130: loss 1.6707, time 1473.20ms, mfu 1.64%\r\n",
      "iter 3140: loss 1.7561, time 1475.10ms, mfu 1.64%\r\n",
      "iter 3150: loss 1.6722, time 1474.28ms, mfu 1.64%\r\n",
      "iter 3160: loss 1.7439, time 1474.25ms, mfu 1.65%\r\n",
      "iter 3170: loss 1.6564, time 1473.56ms, mfu 1.65%\r\n",
      "iter 3180: loss 1.7418, time 1473.78ms, mfu 1.65%\r\n",
      "iter 3190: loss 1.7340, time 1473.83ms, mfu 1.66%\r\n",
      "iter 3200: loss 1.6955, time 1474.83ms, mfu 1.66%\r\n",
      "iter 3210: loss 1.7784, time 1473.71ms, mfu 1.66%\r\n",
      "iter 3220: loss 1.6792, time 1474.68ms, mfu 1.66%\r\n",
      "iter 3230: loss 1.7431, time 1474.67ms, mfu 1.67%\r\n",
      "iter 3240: loss 1.6231, time 1474.03ms, mfu 1.67%\r\n",
      "step 3250: train loss 1.6246, val loss 1.8166\r\n",
      "saving checkpoint to out-shakespeare-char\r\n",
      "iter 3250: loss 1.7701, time 211071.71ms, mfu 1.50%\r\n",
      "iter 3260: loss 1.7066, time 1474.04ms, mfu 1.52%\r\n",
      "iter 3270: loss 1.7544, time 1473.63ms, mfu 1.54%\r\n",
      "iter 3280: loss 1.7033, time 1473.71ms, mfu 1.55%\r\n",
      "iter 3290: loss 1.7561, time 1474.90ms, mfu 1.56%\r\n",
      "iter 3300: loss 1.7625, time 1473.91ms, mfu 1.58%\r\n",
      "iter 3310: loss 1.7121, time 1472.66ms, mfu 1.59%\r\n",
      "iter 3320: loss 1.7258, time 1473.79ms, mfu 1.60%\r\n",
      "iter 3330: loss 1.6599, time 1475.25ms, mfu 1.60%\r\n",
      "iter 3340: loss 1.7188, time 1473.82ms, mfu 1.61%\r\n",
      "iter 3350: loss 1.6968, time 1473.62ms, mfu 1.62%\r\n",
      "iter 3360: loss 1.6749, time 1474.22ms, mfu 1.63%\r\n",
      "iter 3370: loss 1.7044, time 1474.35ms, mfu 1.63%\r\n",
      "iter 3380: loss 1.6650, time 1473.38ms, mfu 1.64%\r\n",
      "iter 3390: loss 1.7023, time 1475.40ms, mfu 1.64%\r\n",
      "iter 3400: loss 1.6933, time 1474.34ms, mfu 1.64%\r\n",
      "iter 3410: loss 1.6507, time 1473.64ms, mfu 1.65%\r\n",
      "iter 3420: loss 1.7163, time 1473.72ms, mfu 1.65%\r\n",
      "iter 3430: loss 1.7082, time 1473.66ms, mfu 1.65%\r\n",
      "iter 3440: loss 1.7522, time 1475.39ms, mfu 1.66%\r\n",
      "iter 3450: loss 1.6890, time 1474.39ms, mfu 1.66%\r\n",
      "iter 3460: loss 1.7867, time 1474.34ms, mfu 1.66%\r\n",
      "iter 3470: loss 1.7055, time 1473.89ms, mfu 1.66%\r\n",
      "iter 3480: loss 1.6992, time 1474.51ms, mfu 1.67%\r\n",
      "iter 3490: loss 1.6700, time 1474.21ms, mfu 1.67%\r\n",
      "step 3500: train loss 1.6076, val loss 1.8066\r\n",
      "saving checkpoint to out-shakespeare-char\r\n",
      "iter 3500: loss 1.7423, time 211230.97ms, mfu 1.50%\r\n",
      "iter 3510: loss 1.7549, time 1474.50ms, mfu 1.52%\r\n",
      "iter 3520: loss 1.7327, time 1473.79ms, mfu 1.54%\r\n",
      "iter 3530: loss 1.7424, time 1474.84ms, mfu 1.55%\r\n",
      "iter 3540: loss 1.6734, time 1474.87ms, mfu 1.56%\r\n",
      "iter 3550: loss 1.6814, time 1474.44ms, mfu 1.58%\r\n",
      "iter 3560: loss 1.6597, time 1474.40ms, mfu 1.59%\r\n",
      "iter 3570: loss 1.6666, time 1474.54ms, mfu 1.60%\r\n",
      "iter 3580: loss 1.6646, time 1474.24ms, mfu 1.60%\r\n",
      "iter 3590: loss 1.6901, time 1473.07ms, mfu 1.61%\r\n",
      "iter 3600: loss 1.6178, time 1474.30ms, mfu 1.62%\r\n",
      "iter 3610: loss 1.6049, time 1474.53ms, mfu 1.62%\r\n",
      "iter 3620: loss 1.6814, time 1474.45ms, mfu 1.63%\r\n",
      "iter 3630: loss 1.7280, time 1474.00ms, mfu 1.64%\r\n",
      "iter 3640: loss 1.7564, time 1474.09ms, mfu 1.64%\r\n",
      "iter 3650: loss 1.7015, time 1473.59ms, mfu 1.64%\r\n",
      "iter 3660: loss 1.7069, time 1474.26ms, mfu 1.65%\r\n",
      "iter 3670: loss 1.6694, time 1473.61ms, mfu 1.65%\r\n",
      "iter 3680: loss 1.7608, time 1474.41ms, mfu 1.65%\r\n",
      "iter 3690: loss 1.5991, time 1474.22ms, mfu 1.66%\r\n",
      "iter 3700: loss 1.6562, time 1474.41ms, mfu 1.66%\r\n",
      "iter 3710: loss 1.6416, time 1474.77ms, mfu 1.66%\r\n",
      "iter 3720: loss 1.7017, time 1475.12ms, mfu 1.66%\r\n",
      "iter 3730: loss 1.6275, time 1474.53ms, mfu 1.67%\r\n",
      "iter 3740: loss 1.7195, time 1474.08ms, mfu 1.67%\r\n",
      "step 3750: train loss 1.5849, val loss 1.7959\r\n",
      "saving checkpoint to out-shakespeare-char\r\n",
      "iter 3750: loss 1.7566, time 211164.76ms, mfu 1.50%\r\n",
      "iter 3760: loss 1.7033, time 1474.80ms, mfu 1.52%\r\n",
      "iter 3770: loss 1.6484, time 1474.18ms, mfu 1.54%\r\n",
      "iter 3780: loss 1.6963, time 1473.66ms, mfu 1.55%\r\n",
      "iter 3790: loss 1.6659, time 1473.74ms, mfu 1.56%\r\n",
      "iter 3800: loss 1.7466, time 1474.11ms, mfu 1.58%\r\n",
      "iter 3810: loss 1.7290, time 1474.90ms, mfu 1.59%\r\n",
      "iter 3820: loss 1.6887, time 1474.38ms, mfu 1.60%\r\n",
      "iter 3830: loss 1.6038, time 1474.12ms, mfu 1.60%\r\n",
      "iter 3840: loss 1.6487, time 1474.80ms, mfu 1.61%\r\n",
      "iter 3850: loss 1.5909, time 1474.67ms, mfu 1.62%\r\n",
      "iter 3860: loss 1.6886, time 1473.94ms, mfu 1.62%\r\n",
      "iter 3870: loss 1.6347, time 1474.82ms, mfu 1.63%\r\n",
      "iter 3880: loss 1.6599, time 1474.47ms, mfu 1.64%\r\n",
      "iter 3890: loss 1.6960, time 1474.18ms, mfu 1.64%\r\n",
      "iter 3900: loss 1.7134, time 1473.67ms, mfu 1.64%\r\n",
      "iter 3910: loss 1.5768, time 1475.15ms, mfu 1.65%\r\n",
      "iter 3920: loss 1.7454, time 1473.89ms, mfu 1.65%\r\n",
      "iter 3930: loss 1.6228, time 1474.34ms, mfu 1.65%\r\n",
      "iter 3940: loss 1.6506, time 1474.28ms, mfu 1.66%\r\n",
      "iter 3950: loss 1.5985, time 1474.16ms, mfu 1.66%\r\n",
      "iter 3960: loss 1.6870, time 1473.09ms, mfu 1.66%\r\n",
      "iter 3970: loss 1.6768, time 1474.92ms, mfu 1.66%\r\n",
      "iter 3980: loss 1.6909, time 1473.93ms, mfu 1.67%\r\n",
      "iter 3990: loss 1.6556, time 1473.50ms, mfu 1.67%\r\n",
      "step 4000: train loss 1.5663, val loss 1.7831\r\n",
      "saving checkpoint to out-shakespeare-char\r\n",
      "iter 4000: loss 1.5525, time 216032.03ms, mfu 1.50%\r\n",
      "iter 4010: loss 1.6695, time 1474.32ms, mfu 1.52%\r\n",
      "iter 4020: loss 1.6809, time 1474.10ms, mfu 1.54%\r\n",
      "iter 4030: loss 1.7120, time 1474.36ms, mfu 1.55%\r\n",
      "iter 4040: loss 1.7179, time 1474.93ms, mfu 1.56%\r\n",
      "iter 4050: loss 1.6393, time 1474.96ms, mfu 1.58%\r\n",
      "iter 4060: loss 1.6782, time 1473.81ms, mfu 1.59%\r\n",
      "iter 4070: loss 1.5976, time 1474.74ms, mfu 1.60%\r\n",
      "iter 4080: loss 1.6783, time 1474.69ms, mfu 1.60%\r\n",
      "iter 4090: loss 1.6914, time 1473.78ms, mfu 1.61%\r\n",
      "iter 4100: loss 1.6156, time 1474.41ms, mfu 1.62%\r\n",
      "iter 4110: loss 1.6879, time 1475.07ms, mfu 1.62%\r\n",
      "iter 4120: loss 1.6533, time 1473.89ms, mfu 1.63%\r\n",
      "iter 4130: loss 1.6091, time 1474.10ms, mfu 1.64%\r\n",
      "iter 4140: loss 1.6889, time 1474.33ms, mfu 1.64%\r\n",
      "iter 4150: loss 1.6412, time 1474.48ms, mfu 1.64%\r\n",
      "iter 4160: loss 1.6348, time 1474.57ms, mfu 1.65%\r\n",
      "iter 4170: loss 1.6912, time 1473.99ms, mfu 1.65%\r\n",
      "iter 4180: loss 1.6481, time 1473.68ms, mfu 1.65%\r\n",
      "iter 4190: loss 1.6635, time 1473.67ms, mfu 1.66%\r\n",
      "iter 4200: loss 1.6774, time 1473.79ms, mfu 1.66%\r\n",
      "iter 4210: loss 1.6133, time 1474.68ms, mfu 1.66%\r\n",
      "iter 4220: loss 1.6365, time 1474.61ms, mfu 1.66%\r\n",
      "iter 4230: loss 1.6576, time 1474.02ms, mfu 1.67%\r\n",
      "iter 4240: loss 1.6679, time 1473.79ms, mfu 1.67%\r\n",
      "step 4250: train loss 1.5535, val loss 1.7700\r\n",
      "saving checkpoint to out-shakespeare-char\r\n",
      "iter 4250: loss 1.7042, time 215354.57ms, mfu 1.50%\r\n",
      "iter 4260: loss 1.6438, time 1474.70ms, mfu 1.52%\r\n",
      "iter 4270: loss 1.6519, time 1475.31ms, mfu 1.54%\r\n",
      "iter 4280: loss 1.6266, time 1474.11ms, mfu 1.55%\r\n",
      "iter 4290: loss 1.6902, time 1474.75ms, mfu 1.56%\r\n",
      "iter 4300: loss 1.5572, time 1474.31ms, mfu 1.58%\r\n",
      "iter 4310: loss 1.6628, time 1473.93ms, mfu 1.59%\r\n",
      "iter 4320: loss 1.6602, time 1473.50ms, mfu 1.60%\r\n",
      "iter 4330: loss 1.6290, time 1475.00ms, mfu 1.60%\r\n",
      "iter 4340: loss 1.6424, time 1474.64ms, mfu 1.61%\r\n",
      "iter 4350: loss 1.6781, time 1473.75ms, mfu 1.62%\r\n",
      "iter 4360: loss 1.6806, time 1474.37ms, mfu 1.62%\r\n",
      "iter 4370: loss 1.6246, time 1474.12ms, mfu 1.63%\r\n",
      "iter 4380: loss 1.6673, time 1474.21ms, mfu 1.64%\r\n",
      "iter 4390: loss 1.6531, time 1474.15ms, mfu 1.64%\r\n",
      "iter 4400: loss 1.6040, time 1474.13ms, mfu 1.64%\r\n",
      "iter 4410: loss 1.6417, time 1474.94ms, mfu 1.65%\r\n",
      "iter 4420: loss 1.6700, time 1474.15ms, mfu 1.65%\r\n",
      "iter 4430: loss 1.6421, time 1474.36ms, mfu 1.65%\r\n",
      "iter 4440: loss 1.6141, time 1474.49ms, mfu 1.66%\r\n",
      "iter 4450: loss 1.6272, time 1474.18ms, mfu 1.66%\r\n",
      "iter 4460: loss 1.6693, time 1473.52ms, mfu 1.66%\r\n",
      "iter 4470: loss 1.6241, time 1474.93ms, mfu 1.66%\r\n",
      "iter 4480: loss 1.6119, time 1474.85ms, mfu 1.67%\r\n",
      "iter 4490: loss 1.5901, time 1473.86ms, mfu 1.67%\r\n",
      "step 4500: train loss 1.5376, val loss 1.7675\r\n",
      "saving checkpoint to out-shakespeare-char\r\n",
      "iter 4500: loss 1.6488, time 212036.52ms, mfu 1.50%\r\n",
      "iter 4510: loss 1.6739, time 1475.64ms, mfu 1.52%\r\n",
      "iter 4520: loss 1.6396, time 1474.10ms, mfu 1.54%\r\n",
      "iter 4530: loss 1.5695, time 1473.94ms, mfu 1.55%\r\n",
      "iter 4540: loss 1.6584, time 1473.30ms, mfu 1.56%\r\n",
      "iter 4550: loss 1.6263, time 1474.06ms, mfu 1.58%\r\n",
      "iter 4560: loss 1.6919, time 1474.82ms, mfu 1.59%\r\n",
      "iter 4570: loss 1.6086, time 1474.28ms, mfu 1.60%\r\n",
      "iter 4580: loss 1.6009, time 1474.01ms, mfu 1.60%\r\n",
      "iter 4590: loss 1.5818, time 1474.85ms, mfu 1.61%\r\n",
      "iter 4600: loss 1.6016, time 1474.98ms, mfu 1.62%\r\n",
      "iter 4610: loss 1.5575, time 1474.19ms, mfu 1.62%\r\n",
      "iter 4620: loss 1.5887, time 1474.77ms, mfu 1.63%\r\n",
      "iter 4630: loss 1.6032, time 1474.95ms, mfu 1.64%\r\n",
      "iter 4640: loss 1.7051, time 1474.77ms, mfu 1.64%\r\n",
      "iter 4650: loss 1.6288, time 1475.12ms, mfu 1.64%\r\n",
      "iter 4660: loss 1.6517, time 1475.52ms, mfu 1.65%\r\n",
      "iter 4670: loss 1.6038, time 1474.46ms, mfu 1.65%\r\n",
      "iter 4680: loss 1.5960, time 1474.83ms, mfu 1.65%\r\n",
      "iter 4690: loss 1.5802, time 1474.80ms, mfu 1.66%\r\n",
      "iter 4700: loss 1.6570, time 1473.90ms, mfu 1.66%\r\n",
      "iter 4710: loss 1.5906, time 1474.95ms, mfu 1.66%\r\n",
      "iter 4720: loss 1.5863, time 1475.42ms, mfu 1.66%\r\n",
      "iter 4730: loss 1.6423, time 1474.24ms, mfu 1.66%\r\n",
      "iter 4740: loss 1.5328, time 1474.52ms, mfu 1.67%\r\n",
      "step 4750: train loss 1.5282, val loss 1.7568\r\n",
      "saving checkpoint to out-shakespeare-char\r\n",
      "iter 4750: loss 1.6637, time 211949.90ms, mfu 1.50%\r\n",
      "iter 4760: loss 1.6716, time 1476.56ms, mfu 1.52%\r\n",
      "iter 4770: loss 1.5717, time 1474.27ms, mfu 1.54%\r\n",
      "iter 4780: loss 1.5947, time 1474.23ms, mfu 1.55%\r\n",
      "iter 4790: loss 1.6779, time 1473.57ms, mfu 1.56%\r\n",
      "iter 4800: loss 1.5654, time 1474.07ms, mfu 1.57%\r\n",
      "iter 4810: loss 1.6052, time 1473.57ms, mfu 1.59%\r\n",
      "iter 4820: loss 1.6018, time 1475.59ms, mfu 1.60%\r\n",
      "iter 4830: loss 1.6312, time 1475.09ms, mfu 1.60%\r\n",
      "iter 4840: loss 1.6010, time 1475.52ms, mfu 1.61%\r\n",
      "iter 4850: loss 1.6178, time 1475.44ms, mfu 1.62%\r\n",
      "iter 4860: loss 1.6364, time 1474.10ms, mfu 1.62%\r\n",
      "iter 4870: loss 1.6828, time 1474.78ms, mfu 1.63%\r\n",
      "iter 4880: loss 1.6514, time 1474.15ms, mfu 1.64%\r\n",
      "iter 4890: loss 1.6267, time 1474.78ms, mfu 1.64%\r\n",
      "iter 4900: loss 1.5394, time 1473.77ms, mfu 1.64%\r\n",
      "iter 4910: loss 1.5979, time 1473.70ms, mfu 1.65%\r\n",
      "iter 4920: loss 1.6757, time 1474.64ms, mfu 1.65%\r\n",
      "iter 4930: loss 1.6188, time 1474.57ms, mfu 1.65%\r\n",
      "iter 4940: loss 1.5767, time 1473.83ms, mfu 1.66%\r\n",
      "iter 4950: loss 1.6382, time 1474.44ms, mfu 1.66%\r\n",
      "iter 4960: loss 1.5892, time 1474.03ms, mfu 1.66%\r\n",
      "iter 4970: loss 1.5770, time 1474.29ms, mfu 1.66%\r\n",
      "iter 4980: loss 1.6652, time 1473.17ms, mfu 1.67%\r\n",
      "iter 4990: loss 1.5036, time 1474.19ms, mfu 1.67%\r\n",
      "step 5000: train loss 1.5206, val loss 1.7386\r\n",
      "saving checkpoint to out-shakespeare-char\r\n",
      "iter 5000: loss 1.6488, time 212086.15ms, mfu 1.50%\r\n",
      "[loss curves saved], out-shakespeare-char/loss_curves.png\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py config/train_shakespeare_char.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24681f42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T07:23:34.537777Z",
     "iopub.status.busy": "2025-11-05T07:23:34.537501Z",
     "iopub.status.idle": "2025-11-05T07:27:39.217973Z",
     "shell.execute_reply": "2025-11-05T07:27:39.217052Z"
    },
    "papermill": {
     "duration": 244.704513,
     "end_time": "2025-11-05T07:27:39.219729",
     "exception": false,
     "start_time": "2025-11-05T07:23:34.515216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-shakespeare-char\r\n",
      "number of parameters: 302.11M\r\n",
      "Loading meta from data/shakespeare_char/meta.pkl...\r\n",
      "\r\n",
      "The wordere all a wife too my prove\r\n",
      "Of you take be fries my lett drust with spress\r\n",
      "your mine, and death their from which your sorrows,\r\n",
      "'Tis them touch to-more in where shall be revenged to have he\r\n",
      "So the in he stiff to seemies of even.\r\n",
      "\r\n",
      "DUKE VINCENTIO:\r\n",
      "I have have the sup thanks; I'll prince.\r\n",
      "\r\n",
      "GLOUCENTIO:\r\n",
      "Not shall pray, what is me have you are have a bed prinard, and so?\r\n",
      "\r\n",
      "PAULIET:\r\n",
      "A shall you perord.\r\n",
      "\r\n",
      "Pray very there baddeny matter,--for it.\r\n",
      "\r\n",
      "PAULIET:\r\n",
      "I me he know you with thou so may a take er\r\n",
      "---------------\r\n",
      "\r\n",
      "First Signant:\r\n",
      "Where to-my love the goody to pake.\r\n",
      "\r\n",
      "KING RICHARD II:\r\n",
      "Yo think they hast of thou read thou with your:\r\n",
      "A pleast throwlet the son ower's ply and Clife,\r\n",
      "We king of thy giver hard ropen all of your\r\n",
      "As empand new queen. Les oberse wordsh do my loverencess go more\r\n",
      "To the do lawfull night, right the was and\r\n",
      "To have the was dead: to the eart of head says;\r\n",
      "Not burging they am to bark the hand blare.\r\n",
      "\r\n",
      "CLIFFORD:\r\n",
      "O, spray thy see in to fration a face:\r\n",
      "Norfolk good his confold by York over, I'\r\n",
      "---------------\r\n",
      "\r\n",
      "First Senator:\r\n",
      "What as play, thou shall not is not?\r\n",
      "\r\n",
      "MENENIUS:\r\n",
      "Ay, because time, lease to be me with a counts\r\n",
      "A make and it is this buse is not be ture.\r\n",
      "\r\n",
      "CORIOLANUS:\r\n",
      "He ving fries made.\r\n",
      "\r\n",
      "MENENIUS:\r\n",
      "This at is then his purpost for yourself, wis\r\n",
      "In him the eased: and not the seast comes gentleman's preself:\r\n",
      "Which guesmile condie likentlest the and been wife\r\n",
      "Whose have beloving as our gagest of their and me of that have he sinnity\r\n",
      "Fears in his deat fave at say him the pride ment;\r\n",
      "And endly as the pa\r\n",
      "---------------\r\n",
      "\r\n",
      "Go the hope be his death\r\n",
      "His flood good as no of first the blood in of it;\r\n",
      "How bound flows and a canning fought: for I am so provost.\r\n",
      "\r\n",
      "LADY ANNE:\r\n",
      "I lord, 'tis thou art hope.\r\n",
      "\r\n",
      "KING RICHARD III:\r\n",
      "Were, what then, how'st the grace alread with unforth:\r\n",
      "Andly heave more lords my down stadfulliatesband betwerer son\r\n",
      "So deadly passion. Henry said my he dead.\r\n",
      "\r\n",
      "PULET:\r\n",
      "Yea, is this in Reconsentry, helm lord.\r\n",
      "\r\n",
      "GLOUCESTER:\r\n",
      "So do be after office heart Merry,\r\n",
      "Welcome to dreat is to Truck you noble my did ence: \r\n",
      "---------------\r\n",
      "\r\n",
      "She crave fearlion me had should to made;\r\n",
      "For me a marranges so bloods flate, and of from call thee,\r\n",
      "To cannot me profess'd hather thrown and humbriolance.\r\n",
      "\r\n",
      "HENRY BOLINGBROKE:\r\n",
      "In the thing of the spose him,\r\n",
      "Take but her have and in will stranter,\r\n",
      "And the twant York shall shore my had.\r\n",
      "\r\n",
      "HENRY BOLINGBROKE:\r\n",
      "Good Boy, son.\r\n",
      "\r\n",
      "GLOUCESTER:\r\n",
      "Ay, but to bawby your fault your good of man,\r\n",
      "A has at was eartices, that one hour gries stand of scess hunds:\r\n",
      "No have we be good all of my lords lady prepart to maid\r\n",
      "---------------\r\n",
      "\r\n",
      "But I heare me all own thos\r\n",
      "Arms bodies fair deation doth pers ther and been-bostate;\r\n",
      "For these traise and is of the who spard it,\r\n",
      "When it of sould heart be,\r\n",
      "So ver have I do the storn.\r\n",
      "\r\n",
      "Shepherd:\r\n",
      "Fore are but think turn, have:\r\n",
      "Why king of the depard to thenought of the crave:\r\n",
      "We hear; wilt you same, good far I words,\r\n",
      "As will you'll then of forgess'd are prock,\r\n",
      "In upon excorself the gifter.\r\n",
      "\r\n",
      "First Murderer:\r\n",
      "Where, I with a will discept her us any be the everth\r\n",
      "Let lity have shall not to liver mi\r\n",
      "---------------\r\n",
      "\r\n",
      "A from but me is from you,\r\n",
      "For the his I am to my lady say ther of a passes,\r\n",
      "The praight for love's to lame.\r\n",
      "\r\n",
      "PRINA:\r\n",
      "O, in so lies speak,\r\n",
      "Then our new--\r\n",
      "\r\n",
      "WARWICK:\r\n",
      "Why, my lord, and yet to help ther heart\r\n",
      "My lady mars the base and to hath-bringlimble not of them and die, good, liege.\r\n",
      "\r\n",
      "QUEEN ELIZABETH:\r\n",
      "Ay, thy weart Pland comford,\r\n",
      "Tour lady hathere bearn I do had was the son,\r\n",
      "And I'll by them I day have prother lack'd them mine and here\r\n",
      "To the knave your his father wrance!\r\n",
      "\r\n",
      "FRIAR AUMERLE:\r\n",
      "What hav\r\n",
      "---------------\r\n",
      "\r\n",
      "First Citizen:\r\n",
      "Like that shall I withis thee friend his blood,\r\n",
      "With that's disg honoul mout us.\r\n",
      "\r\n",
      "POLIXENES:\r\n",
      "This shall have I prince veriar backs.\r\n",
      "\r\n",
      "ANGELO:\r\n",
      "In them the of his fairtuarding procks, and befor live:\r\n",
      "Nor the madam, and it in the may revirter\r\n",
      "To this that shall my to us blooks! what the dish\r\n",
      "If the Coping of that flow.\r\n",
      "\r\n",
      "CORIOLANUS:\r\n",
      "If twell, let that he do in a day.\r\n",
      "\r\n",
      "SICINIUS:\r\n",
      "I woe.\r\n",
      "\r\n",
      "CORIOLANUS:\r\n",
      "Away, 'tis not well gold hear other, my prespity,\r\n",
      "And to lear me. And there the do the my\r\n",
      "---------------\r\n",
      "\r\n",
      "Third with the so lor hand you hast will in you.\r\n",
      "\r\n",
      "KING RICHARD III:\r\n",
      "No let noble my my lord.\r\n",
      "\r\n",
      "DUCHESS OF YORK:\r\n",
      "A minder don, he stop-dam hight day,\r\n",
      "Trangs this the king of alouch hear. Welcomfor that speak;\r\n",
      "How is speaks I shall swortune word your his.\r\n",
      "\r\n",
      "LADY CAPULET:\r\n",
      "And be not.\r\n",
      "\r\n",
      "KING EDWARD II:\r\n",
      "All that will in vise, there the Kingby this power.\r\n",
      "\r\n",
      "GLOUCESTER:\r\n",
      "Why, as conting, that for a grace the have of York\r\n",
      "Let a some all repose oathe mean,\r\n",
      "And by for you prove Geor stand the lamazens no deat,\r\n",
      "---------------\r\n",
      "\r\n",
      "\r\n",
      "ANGELO:\r\n",
      "Beticest, that's sweep thing will the in sity\r\n",
      "God the bosome such of the fretch'd that live\r\n",
      "To the him; the matter the king all way. Whose I have thee.\r\n",
      "\r\n",
      "CAPULET:\r\n",
      "my fair and grace as I beholess' you commerry\r\n",
      "And them and swere the wast your your her me bog death.\r\n",
      "\r\n",
      "CAPULET:\r\n",
      "Ay, let's let is said what will not did?\r\n",
      "\r\n",
      "COMINIUS:\r\n",
      "I will word, what As stand you that keep you\r\n",
      "Of comenter withere of there to ther, but the to shalf the reprouns\r\n",
      "This all and at of my like a like intice of of\r\n",
      "The s\r\n",
      "---------------\r\n",
      "Samples saved to: out-shakespeare-char/samples_123456_20251105-072345.txt\r\n"
     ]
    }
   ],
   "source": [
    "!python sample.py --out_dir=out-shakespeare-char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fd940ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T07:27:39.266493Z",
     "iopub.status.busy": "2025-11-05T07:27:39.266244Z",
     "iopub.status.idle": "2025-11-05T07:27:39.272731Z",
     "shell.execute_reply": "2025-11-05T07:27:39.272090Z"
    },
    "papermill": {
     "duration": 0.030301,
     "end_time": "2025-11-05T07:27:39.273739",
     "exception": false,
     "start_time": "2025-11-05T07:27:39.243438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='/kaggle/working/p1/src/out-shakespeare-char/ckpt.pt' target='_blank'>/kaggle/working/p1/src/out-shakespeare-char/ckpt.pt</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/p1/src/out-shakespeare-char/ckpt.pt"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('/kaggle/working/p1/src/out-shakespeare-char/ckpt.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82e8a4fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T07:27:39.318172Z",
     "iopub.status.busy": "2025-11-05T07:27:39.317963Z",
     "iopub.status.idle": "2025-11-05T07:30:36.177497Z",
     "shell.execute_reply": "2025-11-05T07:30:36.176526Z"
    },
    "papermill": {
     "duration": 176.906741,
     "end_time": "2025-11-05T07:30:36.202183",
     "exception": false,
     "start_time": "2025-11-05T07:27:39.295442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ...\n",
      " model_ckpt.zip3211.16 MB\n",
      "\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='/kaggle/working/model_ckpt.zip' target='_blank'>/kaggle/working/model_ckpt.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/model_ckpt.zip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  ckpt.pt  zip \n",
    "original_file = \"/kaggle/working/p1/src/out-shakespeare-char/ckpt.pt\"\n",
    "zip_file = \"/kaggle/working/model_ckpt.zip\"\n",
    "\n",
    "print(\" ...\")\n",
    "!zip -q -9 \"{zip_file}\" \"{original_file}\"  # -9 \n",
    "\n",
    "# \n",
    "if os.path.exists(zip_file):\n",
    "    zip_size = round(os.path.getsize(zip_file)/1024/1024, 2)\n",
    "    print(f\" {os.path.basename(zip_file)}{zip_size} MB\")\n",
    "    print(\"\\n \")\n",
    "    display(FileLink(zip_file))\n",
    "else:\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2d3c4e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T07:30:36.248315Z",
     "iopub.status.busy": "2025-11-05T07:30:36.247644Z",
     "iopub.status.idle": "2025-11-05T07:30:36.252844Z",
     "shell.execute_reply": "2025-11-05T07:30:36.252113Z"
    },
    "papermill": {
     "duration": 0.029281,
     "end_time": "2025-11-05T07:30:36.253877",
     "exception": false,
     "start_time": "2025-11-05T07:30:36.224596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Path (<tt>/kaggle/working/ckpt.pt</tt>) doesn't exist. It may still be in the process of being generated, or you may have the incorrect path."
      ],
      "text/plain": [
       "/kaggle/working/ckpt.pt"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('/kaggle/working/ckpt.pt')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8645615,
     "sourceId": 13605481,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12231.034912,
   "end_time": "2025-11-05T07:30:36.693161",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-05T04:06:45.658249",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
